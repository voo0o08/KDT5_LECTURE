{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer test하는 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 테이블의 데이터수는 총 31102개 입니다.\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "\n",
    "# 데이터 베이스 연결하기\n",
    "conn = pymysql.connect(host='1.251.203.204',\n",
    "                       user='root',\n",
    "                       password='kdt5',\n",
    "                       db='Team4',\n",
    "                       charset='utf8',\n",
    "                       port=33065)\n",
    "\n",
    "curs = conn.cursor()\n",
    "\n",
    "# 검색 명령어 사용 \n",
    "sql = \"SELECT eng.text as eng_text, kor.text as kor_text FROM language_en eng join language_ko kor on eng.id = kor.id;\"\n",
    "curs.execute(sql)\n",
    "result = curs.fetchall()\n",
    "print(\"현재 테이블의 데이터수는 총 {}개 입니다.\".format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdp\\AppData\\Local\\Temp\\ipykernel_24736\\3967427127.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_sql(sql, conn)\n",
    "\n",
    "# 데이터베이스 연결 종료\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(df) * 0.8)  # 전체 데이터 중 80%를 훈련 데이터셋으로 사용\n",
    "train_df = df.iloc[:split_idx]\n",
    "valid_df = df.iloc[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kdp\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torchtext\\data\\utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Transform:\n",
      "{'eng': functools.partial(<function _spacy_tokenize at 0x000002594BC2CAF0>, spacy=<spacy.lang.en.English object at 0x00000259459E6910>), 'kor': <bound method Okt.morphs of <konlpy.tag._okt.Okt object at 0x000002594D2348B0>>}\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "\n",
    "def generate_tokens(text_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for text in text_iter:\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = \"eng\"\n",
    "TGT_LANGUAGE = \"kor\"\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3 # 알 수 없음 / 패딩 / 인덱스 시작 / 인덱스 끝 \n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"en\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(Okt().morphs),\n",
    "}\n",
    "print(\"Token Transform:\")\n",
    "print(token_transform)\n",
    "\n",
    "# vocab_transform = {} # 딕셔너리 {\"eng\":어쩌구, \"kor\":저쩌구}\n",
    "train_iter = train_df.values # 현길사마가 도와준 부분 \n",
    "val_iter = valid_df.values\n",
    "\n",
    "# for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "#     # train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "#     vocab_transform[language] = build_vocab_from_iterator(\n",
    "#         generate_tokens(train_iter, language),\n",
    "#         min_freq=1, # 토큰화된 단어들의 최소 빈도수 지정 \n",
    "#         specials=special_symbols, # 트랜스포머에 사용하는 특수토큰 [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "#         special_first=True, # 특수 토큰을 단어 집합의 맨 앞에 추가 \n",
    "#     )\n",
    "\n",
    "# for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "#     vocab_transform[language].set_default_index(UNK_IDX)\n",
    "\n",
    "# print(\"Vocab Transform:\")\n",
    "# print(vocab_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# # 파일에 vocab_transform 저장\n",
    "# torch.save(vocab_transform, './model/vocab_transform.pth')\n",
    "\n",
    "# 파일에서 vocab_transform 불러오기\n",
    "vocab_transform = torch.load('./model/vocab_transform.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import optim\n",
    "# from torchinfo import summary\n",
    "\n",
    "# BATCH_SIZE = 128\n",
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(DEVICE)\n",
    "\n",
    "# model = Seq2SeqTransformer(\n",
    "#     num_encoder_layers=6,\n",
    "#     num_decoder_layers=6,\n",
    "#     emb_size=8,\n",
    "#     max_len=128,\n",
    "#     nhead=8,\n",
    "#     src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "#     tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "#     dim_feedforward=512,\n",
    "# ).to(DEVICE)\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# summary(model)\n",
    "# # for main_name, main_module in model.named_children():\n",
    "# #     print(main_name)\n",
    "# #     for sub_name, sub_module in main_module.named_children():\n",
    "# #         print(\"└\", sub_name)\n",
    "# #         for ssub_name, ssub_module in sub_module.named_children():\n",
    "# #             print(\"│  └\", ssub_name)\n",
    "# #             for sssub_name, sssub_module in ssub_module.named_children():\n",
    "# #                 print(\"│  │  └\", sssub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 포지셔 \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# TokenEmbedding 클래스로 소스 데이터와 입력 데이터를 입력 임베딩으로 변환\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        emb_size,\n",
    "        max_len,\n",
    "        nhead,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        dim_feedforward,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=emb_size, max_len=max_len, dropout=dropout\n",
    "        )\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        trg,\n",
    "        src_mask,\n",
    "        tgt_mask,\n",
    "        src_padding_mask,\n",
    "        tgt_padding_mask,\n",
    "        memory_key_padding_mask,\n",
    "    ):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(\n",
    "            src=src_emb,\n",
    "            tgt=tgt_emb,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=None,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kdp\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\kdp\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "Seq2SeqTransformer                                                     --\n",
       "├─TokenEmbedding: 1-1                                                  --\n",
       "│    └─Embedding: 2-1                                                  1,515,904\n",
       "├─TokenEmbedding: 1-2                                                  --\n",
       "│    └─Embedding: 2-2                                                  3,174,912\n",
       "├─PositionalEncoding: 1-3                                              --\n",
       "│    └─Dropout: 2-3                                                    --\n",
       "├─Transformer: 1-4                                                     --\n",
       "│    └─TransformerEncoder: 2-4                                         --\n",
       "│    │    └─ModuleList: 3-1                                            594,816\n",
       "│    │    └─LayerNorm: 3-2                                             256\n",
       "│    └─TransformerDecoder: 2-5                                         --\n",
       "│    │    └─ModuleList: 3-3                                            793,728\n",
       "│    │    └─LayerNorm: 3-4                                             256\n",
       "├─Linear: 1-5                                                          3,199,716\n",
       "===============================================================================================\n",
       "Total params: 9,279,588\n",
       "Trainable params: 9,279,588\n",
       "Non-trainable params: 0\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torchinfo import summary\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    emb_size=128,\n",
    "    max_len=128,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "summary(model)\n",
    "# for main_name, main_module in model.named_children():\n",
    "#     print(main_name)\n",
    "#     for sub_name, sub_module in main_module.named_children():\n",
    "#         print(\"└\", sub_name)\n",
    "#         for ssub_name, ssub_module in sub_module.named_children():\n",
    "#             print(\"│  └\", ssub_name)\n",
    "#             for sssub_name, sssub_module in ssub_module.named_children():\n",
    "#                 print(\"│  │  └\", sssub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(source, target):\n",
      "['And they went out quickly, and fled from the sepulchre; for they trembled and were amazed: neither said they any thing to any man; for they were afraid.'\n",
      " '여자들이 심히 놀라 떨며 나와 무덤에서 도망하고 무서워하여 아무에게 아무 말도 하지 못하더라']\n",
      "source_batch: torch.Size([53, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  10,  183,   10,  ...,   10,   10,  542],\n",
      "        [  23,   60,  118,  ...,  349, 1208,  768],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "target_batch: torch.Size([47, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [ 317,  559, 2592,  ...,    7, 1243,   51],\n",
      "        [  11,  142,    9,  ..., 1217,    4,  181],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def input_transform(token_ids):\n",
    "    return torch.cat(\n",
    "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX]))\n",
    "    )\n",
    "\n",
    "def collator(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "text_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[language] = sequential_transforms(\n",
    "        token_transform[language], vocab_transform[language], input_transform\n",
    "    )\n",
    "\n",
    "# data_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collator) # data_iter가 데이터셋인듯\n",
    "source_tensor, target_tensor = next(iter(dataloader)) \n",
    "\n",
    "print(\"(source, target):\")\n",
    "print(next(iter(val_iter)))\n",
    "\n",
    "print(\"source_batch:\", source_tensor.shape)\n",
    "print(source_tensor)\n",
    "\n",
    "print(\"target_batch:\", target_tensor.shape)\n",
    "print(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_mask: torch.Size([53, 53])\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "target_mask: torch.Size([46, 46])\n",
      "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "source_padding_mask: torch.Size([128, 53])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n",
      "target_padding_mask: torch.Size([128, 46])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(s):\n",
    "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "target_input = target_tensor[:-1, :]\n",
    "target_out = target_tensor[1:, :]\n",
    "\n",
    "source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n",
    "    source_tensor, target_input\n",
    ")\n",
    "\n",
    "print(\"source_mask:\", source_mask.shape)\n",
    "print(source_mask)\n",
    "print(\"target_mask:\", target_mask.shape)\n",
    "print(target_mask)\n",
    "print(\"source_padding_mask:\", source_padding_mask.shape)\n",
    "print(source_padding_mask)\n",
    "print(\"target_padding_mask:\", target_padding_mask.shape)\n",
    "print(target_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(11843, 128)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(24804, 128)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=128, out_features=24804, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = Seq2SeqTransformer(\n",
    "#     num_encoder_layers=3,\n",
    "#     num_decoder_layers=3,\n",
    "#     emb_size=8,\n",
    "#     max_len=128,\n",
    "#     nhead=8,\n",
    "#     src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "#     tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "#     dim_feedforward=512,\n",
    "# ).to(DEVICE)\n",
    "# optimizer = optim.Adam(model.parameters()) # , lr=0.1\n",
    "\n",
    "checkpoint = torch.load('./model/eng2kor2.pth',  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n",
    "    source_tensor = source_tensor.to(DEVICE)\n",
    "    source_mask = source_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(source_tensor, source_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        target_mask = generate_square_subsequent_mask(ys.size(0))\n",
    "        target_mask = target_mask.type(torch.bool).to(DEVICE)\n",
    "\n",
    "        out = model.decode(ys, memory, target_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model, source_sentence):\n",
    "    model.eval()\n",
    "    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1)\n",
    "    num_tokens = source_tensor.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))[1:-1]\n",
    "    return \" \".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예수 께서 제자 들 에게 이르시되 너희 가 떡 을 살것이 떡 을 가지사 축사 하시고\n",
      "예수 께서 제자 들 에게 이르시되 너희 가 어찌하여 성전 에 들어가기가 어려우니라\n"
     ]
    }
   ],
   "source": [
    "# 태초에 하나님이 천지를 창조하시니라\n",
    "output_oov = translate(model, \"In the beginning God created the pasta and the pizza.\") # 없는 단어\n",
    "output = translate(model, \"In the beginning God created the heaven and the earth.\")\n",
    "print(output_oov)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예수 께서 가라사대 너희 가 성경 에 씨 를 너희 에게 비유 를 너희 에게 비유 를 너희 에게\n"
     ]
    }
   ],
   "source": [
    "# And God said, Let there be light: and there was light.\n",
    "output = translate(model, \"And God said, Let there be light: and there was light.\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
