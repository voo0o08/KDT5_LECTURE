{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### softmax(), sigmoid() 함수 -> one-hot  encoding 안 한 ver\n",
    "- sigmoid() : y = wx+b 결과물 전달 => 반환 : 0.0~1.0 사이 값으로 변환 \n",
    "- softmax() : y = wx+b 여러 개 전달 => 반환 : 여러 개의 결과값의 합이 1.0이 되도록 변환 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70f6381d7ecefe09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 모듈 로딩 \n",
    "import torch # torch 기본 모듈로 텐서 기본 함수들 \n",
    "import torch.nn.functional as F # pytorch 인공 신경망 관련 함수들 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:29:46.365436700Z",
     "start_time": "2024-03-14T01:29:44.430496300Z"
    }
   },
   "id": "4dbdd994ec9f3055",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의 데이터 생성\n",
    "data1 = torch.tensor([1, 2, 1, 1, 2])\n",
    "data1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:30:11.176645700Z",
     "start_time": "2024-03-14T01:30:11.158003400Z"
    }
   },
   "id": "3809fc9daa77108b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.7311, 0.8808, 0.7311, 0.7311, 0.8808])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(data1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:31:00.168805800Z",
     "start_time": "2024-03-14T01:31:00.143952800Z"
    }
   },
   "id": "ab212c0358c5cab9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.3685, -1.4700, -1.0484],\n        [ 0.6128, -0.4372, -1.0753]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 3)\n",
    "input # 만약 이게 분류기(softmax)에서 나온 값이라면 한 행의 합은 1이어야함"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:37:37.494170100Z",
     "start_time": "2024-03-14T01:37:37.476610300Z"
    }
   },
   "id": "ca6ee3f5eba816fe",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6804, 0.2626, 0.5067],\n        [0.3196, 0.7374, 0.4933]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = F.softmax(input, dim=0)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:41:16.140303300Z",
     "start_time": "2024-03-14T01:41:16.113656900Z"
    }
   },
   "id": "b1ddf517399874f0",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.max(dim=1)[1][0].item() # argmax는 값은 없고 인덱스만 있음"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:42:33.793610100Z",
     "start_time": "2024-03-14T01:42:33.773460600Z"
    }
   },
   "id": "566a46494ce08730",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 이미지 데이터 - 이진분류 모델\n",
    "- 데이터셋 : fashion mnist\n",
    "- 피쳐개수 : 28X28 784개\n",
    "- 타겟 개수 : 0~9 티셔츠, 바지, 풀오버 ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc4abfebdaf73b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모듈 로딩 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dede4f77d934c96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # linear Regression 기능의 클래스 Linear\n",
    "import torch.nn.functional as F # 손실함수를 위함\n",
    "import torch.optim as optim # 최적화를 위함"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:47:46.069973900Z",
     "start_time": "2024-03-14T01:47:44.626838100Z"
    }
   },
   "id": "49327cb32df9d67",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 준비"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "204c0958e8927867"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "fashion_db = 'fashion-mnist'\n",
    "\n",
    "fashion_data = fetch_openml(name = fashion_db, parser='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:49:07.717045100Z",
     "start_time": "2024-03-14T01:49:04.287397200Z"
    }
   },
   "id": "8cc44141ccd94324",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 데이터 확인 \n",
    "feature = fashion_data['data']\n",
    "target = fashion_data['target']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:50:20.001818Z",
     "start_time": "2024-03-14T01:50:19.991395Z"
    }
   },
   "id": "4f4c2e153968395a",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feares: (70000, 784), 2D\n",
      "target: (70000,), 1D\n"
     ]
    }
   ],
   "source": [
    "# 데이터 피쳐와 타겟 개수 확인 \n",
    "print(f\"feares: {feature.shape}, {feature.ndim}D\")\n",
    "print(f\"target: {target.shape}, {target.ndim}D\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:51:59.476654Z",
     "start_time": "2024-03-14T01:51:59.457594500Z"
    }
   },
   "id": "b37a8ab5af06cb75",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature => ['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783', 'pixel784']\n",
      "target name => ['class']\n",
      "categories => None\n",
      "categories => ['9', '0', '3', '2', '7', '5', '1', '6', '4', '8']\n",
      "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# 분류 확인\n",
    "print(f\"feature => {fashion_data['feature_names']}\")\n",
    "print(f\"target name => {fashion_data['target_names']}\")\n",
    "print(f\"categories => {fashion_data['categories']}\")\n",
    "# 받아올 때 numpy로 받아오면 category로 고유값 확인 가능 \n",
    "# dataframe은 카테고리 무조건 None뜸\n",
    "print(f\"categories => {target.unique()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T01:55:22.259543600Z",
     "start_time": "2024-03-14T01:55:22.239799100Z"
    }
   },
   "id": "19ebd2a1169e2f21",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 데이터 가공 및 전처리\n",
    "- 결측치 없음\n",
    "- 이상치 없음\n",
    "- 중복값 없음 \n",
    "- 다중 분류 => 2진분류 변환 : target 변환\n",
    "- 이미지 크기 맞추기 : 여기서는 필요 없음 28, 28, 1(흑백)\n",
    "- 정규화 : 피쳐 정규화 / 타겟 정규화"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaa633661b885ea0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([ True, False])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일단 2진으로 변환 : target -> mask or replace \n",
    "target = target != \"0\"\n",
    "target.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:03:54.827189200Z",
     "start_time": "2024-03-14T02:03:54.806845200Z"
    }
   },
   "id": "c41b10a93fd97ecf",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       pixel1  pixel2  pixel3  pixel4  pixel5    pixel6  pixel7  pixel8  \\\n0         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n1         0.0     0.0     0.0     0.0     0.0  0.003922     0.0     0.0   \n2         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n3         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n4         0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n...       ...     ...     ...     ...     ...       ...     ...     ...   \n69995     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n69996     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n69997     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n69998     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n69999     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n\n         pixel9   pixel10  ...  pixel775  pixel776  pixel777  pixel778  \\\n0      0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n1      0.000000  0.000000  ...  0.466667  0.447059  0.509804  0.298039   \n2      0.000000  0.086275  ...  0.000000  0.000000  0.003922  0.000000   \n3      0.129412  0.376471  ...  0.000000  0.000000  0.000000  0.000000   \n4      0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n...         ...       ...  ...       ...       ...       ...       ...   \n69995  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n69996  0.000000  0.121569  ...  0.000000  0.000000  0.000000  0.000000   \n69997  0.000000  0.000000  ...  0.105882  0.000000  0.000000  0.000000   \n69998  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n69999  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  pixel784  \n0           0.0       0.0       0.0       0.0       0.0       0.0  \n1           0.0       0.0       0.0       0.0       0.0       0.0  \n2           0.0       0.0       0.0       0.0       0.0       0.0  \n3           0.0       0.0       0.0       0.0       0.0       0.0  \n4           0.0       0.0       0.0       0.0       0.0       0.0  \n...         ...       ...       ...       ...       ...       ...  \n69995       0.0       0.0       0.0       0.0       0.0       0.0  \n69996       0.0       0.0       0.0       0.0       0.0       0.0  \n69997       0.0       0.0       0.0       0.0       0.0       0.0  \n69998       0.0       0.0       0.0       0.0       0.0       0.0  \n69999       0.0       0.0       0.0       0.0       0.0       0.0  \n\n[70000 rows x 784 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>pixel10</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003922</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.466667</td>\n      <td>0.447059</td>\n      <td>0.509804</td>\n      <td>0.298039</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.086275</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003922</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.129412</td>\n      <td>0.376471</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69995</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69996</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.121569</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69997</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.105882</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69998</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>69999</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>70000 rows × 784 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피쳐 : 784개 색상값 즉, 0~255 범위의 값\n",
    "norm_feature = feature/255\n",
    "norm_feature"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:07:50.704755300Z",
     "start_time": "2024-03-14T02:07:50.642930200Z"
    }
   },
   "id": "d8e882e26a823e47",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       False  True \n0      False   True\n1       True  False\n2       True  False\n3      False   True\n4       True  False\n...      ...    ...\n69995  False   True\n69996  False   True\n69997  False   True\n69998  False   True\n69999  False   True\n\n[70000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>False</th>\n      <th>True</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69995</th>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>69996</th>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>69997</th>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>69998</th>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>69999</th>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>70000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2-2] 정규화 : One-Hot 인코딩으로 변환\n",
    "import pandas as pd\n",
    "pd.get_dummies(target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:10:31.630354800Z",
     "start_time": "2024-03-14T02:10:31.603525300Z"
    }
   },
   "id": "c7f5d4f70ba8d01a",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# one-hot 2\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:14:35.487912200Z",
     "start_time": "2024-03-14T02:14:35.469986400Z"
    }
   },
   "id": "5b8ddd3638ef091b",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "targetDF = target.to_frame()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:18:18.519098300Z",
     "start_time": "2024-03-14T02:18:18.500027500Z"
    }
   },
   "id": "f2f2813c52c067f9",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 1.],\n       [1., 0.],\n       [1., 0.],\n       ...,\n       [0., 1.],\n       [0., 1.],\n       [0., 1.]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse_output=False : ndarray 타입으로 반환\n",
    "ohEncoder = OneHotEncoder(sparse_output=False)\n",
    "ohEncoder.fit_transform(targetDF) # one-hot encoder 안에는 꼭 2차원 \n",
    "# 라벨 인코딩은 정수로 바꿔줌 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:18:18.673538600Z",
     "start_time": "2024-03-14T02:18:18.659984300Z"
    }
   },
   "id": "813b4c3665d9bc78",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((70000, 2), 2)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_target = ohEncoder.transform(targetDF)\n",
    "norm_target.shape, norm_target.ndim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T02:19:48.962639500Z",
     "start_time": "2024-03-14T02:19:48.947109100Z"
    }
   },
   "id": "d0cffae3700d50ad",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 텐서화 시키기\n",
    "- 데이터 셋 준비 : 훈련용 60000, 테스트용 10000\n",
    "- 학습 방법 : 지도 학습 - 이진 분류 (Linear 클래스를 sigmoid 함수)\n",
    "- 최적화 방법 : 경사하강법 기반의 방법 (Adam, SDG, )\n",
    "- 손실함수 : 이진분류 손실 계산 함수(binary_cross_entropy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "605f27356c080728"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 데이터셋 준비\n",
    "limit = 60000\n",
    "\n",
    "train = norm_feature.iloc[:limit]\n",
    "test = norm_feature.iloc[limit:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:22:52.503971200Z",
     "start_time": "2024-03-14T04:22:52.485132400Z"
    }
   },
   "id": "2387a57346ff979d",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# one-hot 안한 거 \n",
    "train_y = target[:limit]\n",
    "test_y = target[limit:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:25:26.163746600Z",
     "start_time": "2024-03-14T04:25:26.144097100Z"
    }
   },
   "id": "486e54e22321b2dc",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (60000, 784), 2D\n",
      "train_y: (60000,), 1D\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: {train.shape}, {train.ndim}D\")\n",
    "print(f\"train_y: {train_y.shape}, {train_y.ndim}D\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:26:03.407196500Z",
     "start_time": "2024-03-14T04:26:03.388201200Z"
    }
   },
   "id": "d9fd6b70fdb01078",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(train.values) \n",
    "X_test = torch.FloatTensor(test.values)\n",
    "y_train= torch.FloatTensor(train_y.values).unsqueeze(dim=1)\n",
    "y_test = torch.FloatTensor(test_y.values).unsqueeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:50:41.460959800Z",
     "start_time": "2024-03-14T04:50:41.403504500Z"
    }
   },
   "id": "fad17b765834f010",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([60000, 784]), 2D\n",
      "y_train: torch.Size([60000, 1]), 2D\n",
      "X_test: torch.Size([10000, 784]), 2D\n",
      "y_test: torch.Size([10000, 1]), 2D\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, {X_train.ndim}D\")\n",
    "print(f\"y_train: {y_train.shape}, {y_train.ndim}D\")\n",
    "print(f\"X_test: {X_test.shape}, {X_test.ndim}D\")\n",
    "print(f\"y_test: {y_test.shape}, {y_test.ndim}D\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:50:42.091660200Z",
     "start_time": "2024-03-14T04:50:42.069094600Z"
    }
   },
   "id": "72d6b421388ade2b",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=784, out_features=1, bias=True)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 인스턴스 생성\n",
    "in_, out_ = X_train.shape[1], y_train.shape[1] # 784, 1 -> 원핫 한 걸로 했으면 784, 2\n",
    "model = nn.Linear(in_, out_) # 어제했던 required grad를 얘가 다 해줌 \n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:50:42.275136600Z",
     "start_time": "2024-03-14T04:50:42.242114200Z"
    }
   },
   "id": "4e7f7e90a7d26ab6",
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "위에 걸 보고 W를 만드는 것!! "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea75c32fa633f229"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x000001B32D2D2F90>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:50:42.544155700Z",
     "start_time": "2024-03-14T04:50:42.536571100Z"
    }
   },
   "id": "4db17d753fee4143",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 생성\n",
    "optimizer = optim.Adam(model.parameters()) # model.parameters -> W1, W2, W3...와 bias가 담겨 있음 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:50:44.102796200Z",
     "start_time": "2024-03-14T04:50:42.715234600Z"
    }
   },
   "id": "eb051c9c46bfd8f5",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 학습 횟수 => 샘플 처음부터 끝까지 읽는 것 기준으로 횟수 지정\n",
    "EPOCHS = 150"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T04:50:44.124549200Z",
     "start_time": "2024-03-14T04:50:44.109163800Z"
    }
   },
   "id": "c8fc8bf9af320835",
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 학습\n",
    "- 반복 횟수 만큼 학습 진행 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caa4de126921623d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 pre_y => tensor([[10.7583],\n",
      "        [-3.4671],\n",
      "        [ 1.8101],\n",
      "        ...,\n",
      "        [ 4.2288],\n",
      "        [-0.1674],\n",
      "        [ 3.8645]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0303],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9856],\n",
      "        [0.4583],\n",
      "        [0.9795]], grad_fn=<SigmoidBackward0>)\n",
      "[0] Loss => 0.11826194077730179\n",
      "예측값 pre_y => tensor([[10.7619],\n",
      "        [-3.4683],\n",
      "        [ 1.8102],\n",
      "        ...,\n",
      "        [ 4.2313],\n",
      "        [-0.1677],\n",
      "        [ 3.8665]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0302],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9857],\n",
      "        [0.4582],\n",
      "        [0.9795]], grad_fn=<SigmoidBackward0>)\n",
      "[1] Loss => 0.11823346465826035\n",
      "예측값 pre_y => tensor([[10.7654],\n",
      "        [-3.4695],\n",
      "        [ 1.8103],\n",
      "        ...,\n",
      "        [ 4.2339],\n",
      "        [-0.1681],\n",
      "        [ 3.8685]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0302],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9857],\n",
      "        [0.4581],\n",
      "        [0.9795]], grad_fn=<SigmoidBackward0>)\n",
      "[2] Loss => 0.11820509284734726\n",
      "예측값 pre_y => tensor([[10.7689],\n",
      "        [-3.4707],\n",
      "        [ 1.8104],\n",
      "        ...,\n",
      "        [ 4.2365],\n",
      "        [-0.1684],\n",
      "        [ 3.8705]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0302],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9857],\n",
      "        [0.4580],\n",
      "        [0.9796]], grad_fn=<SigmoidBackward0>)\n",
      "[3] Loss => 0.11817680299282074\n",
      "예측값 pre_y => tensor([[10.7724],\n",
      "        [-3.4719],\n",
      "        [ 1.8105],\n",
      "        ...,\n",
      "        [ 4.2390],\n",
      "        [-0.1687],\n",
      "        [ 3.8725]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0301],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9858],\n",
      "        [0.4579],\n",
      "        [0.9796]], grad_fn=<SigmoidBackward0>)\n",
      "[4] Loss => 0.1181485652923584\n",
      "예측값 pre_y => tensor([[10.7759],\n",
      "        [-3.4731],\n",
      "        [ 1.8106],\n",
      "        ...,\n",
      "        [ 4.2416],\n",
      "        [-0.1691],\n",
      "        [ 3.8744]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0301],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9858],\n",
      "        [0.4578],\n",
      "        [0.9797]], grad_fn=<SigmoidBackward0>)\n",
      "[5] Loss => 0.11812041699886322\n",
      "예측값 pre_y => tensor([[10.7794],\n",
      "        [-3.4742],\n",
      "        [ 1.8107],\n",
      "        ...,\n",
      "        [ 4.2442],\n",
      "        [-0.1694],\n",
      "        [ 3.8764]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0301],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9859],\n",
      "        [0.4577],\n",
      "        [0.9797]], grad_fn=<SigmoidBackward0>)\n",
      "[6] Loss => 0.11809232085943222\n",
      "예측값 pre_y => tensor([[10.7829],\n",
      "        [-3.4754],\n",
      "        [ 1.8107],\n",
      "        ...,\n",
      "        [ 4.2467],\n",
      "        [-0.1698],\n",
      "        [ 3.8784]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0300],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9859],\n",
      "        [0.4577],\n",
      "        [0.9797]], grad_fn=<SigmoidBackward0>)\n",
      "[7] Loss => 0.11806431412696838\n",
      "예측값 pre_y => tensor([[10.7863],\n",
      "        [-3.4766],\n",
      "        [ 1.8108],\n",
      "        ...,\n",
      "        [ 4.2493],\n",
      "        [-0.1701],\n",
      "        [ 3.8803]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0300],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9859],\n",
      "        [0.4576],\n",
      "        [0.9798]], grad_fn=<SigmoidBackward0>)\n",
      "[8] Loss => 0.11803635954856873\n",
      "예측값 pre_y => tensor([[10.7898],\n",
      "        [-3.4777],\n",
      "        [ 1.8109],\n",
      "        ...,\n",
      "        [ 4.2518],\n",
      "        [-0.1704],\n",
      "        [ 3.8823]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0300],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9860],\n",
      "        [0.4575],\n",
      "        [0.9798]], grad_fn=<SigmoidBackward0>)\n",
      "[9] Loss => 0.11800852417945862\n",
      "예측값 pre_y => tensor([[10.7932],\n",
      "        [-3.4789],\n",
      "        [ 1.8109],\n",
      "        ...,\n",
      "        [ 4.2543],\n",
      "        [-0.1708],\n",
      "        [ 3.8842]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0299],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9860],\n",
      "        [0.4574],\n",
      "        [0.9799]], grad_fn=<SigmoidBackward0>)\n",
      "[10] Loss => 0.11798074096441269\n",
      "예측값 pre_y => tensor([[10.7966],\n",
      "        [-3.4800],\n",
      "        [ 1.8110],\n",
      "        ...,\n",
      "        [ 4.2569],\n",
      "        [-0.1711],\n",
      "        [ 3.8862]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0299],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9860],\n",
      "        [0.4573],\n",
      "        [0.9799]], grad_fn=<SigmoidBackward0>)\n",
      "[11] Loss => 0.11795300990343094\n",
      "예측값 pre_y => tensor([[10.8000],\n",
      "        [-3.4812],\n",
      "        [ 1.8111],\n",
      "        ...,\n",
      "        [ 4.2594],\n",
      "        [-0.1715],\n",
      "        [ 3.8881]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0299],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9861],\n",
      "        [0.4572],\n",
      "        [0.9799]], grad_fn=<SigmoidBackward0>)\n",
      "[12] Loss => 0.11792537569999695\n",
      "예측값 pre_y => tensor([[10.8034],\n",
      "        [-3.4823],\n",
      "        [ 1.8111],\n",
      "        ...,\n",
      "        [ 4.2619],\n",
      "        [-0.1718],\n",
      "        [ 3.8900]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0298],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9861],\n",
      "        [0.4572],\n",
      "        [0.9800]], grad_fn=<SigmoidBackward0>)\n",
      "[13] Loss => 0.11789777874946594\n",
      "예측값 pre_y => tensor([[10.8068],\n",
      "        [-3.4834],\n",
      "        [ 1.8112],\n",
      "        ...,\n",
      "        [ 4.2644],\n",
      "        [-0.1721],\n",
      "        [ 3.8920]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0298],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9861],\n",
      "        [0.4571],\n",
      "        [0.9800]], grad_fn=<SigmoidBackward0>)\n",
      "[14] Loss => 0.11787029355764389\n",
      "예측값 pre_y => tensor([[10.8102],\n",
      "        [-3.4845],\n",
      "        [ 1.8112],\n",
      "        ...,\n",
      "        [ 4.2670],\n",
      "        [-0.1725],\n",
      "        [ 3.8939]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0298],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9862],\n",
      "        [0.4570],\n",
      "        [0.9800]], grad_fn=<SigmoidBackward0>)\n",
      "[15] Loss => 0.11784284561872482\n",
      "예측값 pre_y => tensor([[10.8136],\n",
      "        [-3.4857],\n",
      "        [ 1.8112],\n",
      "        ...,\n",
      "        [ 4.2695],\n",
      "        [-0.1728],\n",
      "        [ 3.8958]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0297],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9862],\n",
      "        [0.4569],\n",
      "        [0.9801]], grad_fn=<SigmoidBackward0>)\n",
      "[16] Loss => 0.11781550198793411\n",
      "예측값 pre_y => tensor([[10.8169],\n",
      "        [-3.4868],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 4.2720],\n",
      "        [-0.1732],\n",
      "        [ 3.8977]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0297],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9862],\n",
      "        [0.4568],\n",
      "        [0.9801]], grad_fn=<SigmoidBackward0>)\n",
      "[17] Loss => 0.117788165807724\n",
      "예측값 pre_y => tensor([[10.8203],\n",
      "        [-3.4879],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 4.2745],\n",
      "        [-0.1735],\n",
      "        [ 3.8996]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0297],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9863],\n",
      "        [0.4567],\n",
      "        [0.9802]], grad_fn=<SigmoidBackward0>)\n",
      "[18] Loss => 0.11776096373796463\n",
      "예측값 pre_y => tensor([[10.8236],\n",
      "        [-3.4890],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 4.2770],\n",
      "        [-0.1738],\n",
      "        [ 3.9015]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0296],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9863],\n",
      "        [0.4566],\n",
      "        [0.9802]], grad_fn=<SigmoidBackward0>)\n",
      "[19] Loss => 0.11773378401994705\n",
      "예측값 pre_y => tensor([[10.8269],\n",
      "        [-3.4901],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2795],\n",
      "        [-0.1742],\n",
      "        [ 3.9034]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0296],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9863],\n",
      "        [0.4566],\n",
      "        [0.9802]], grad_fn=<SigmoidBackward0>)\n",
      "[20] Loss => 0.11770671606063843\n",
      "예측값 pre_y => tensor([[10.8302],\n",
      "        [-3.4911],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2820],\n",
      "        [-0.1745],\n",
      "        [ 3.9053]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0296],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9864],\n",
      "        [0.4565],\n",
      "        [0.9803]], grad_fn=<SigmoidBackward0>)\n",
      "[21] Loss => 0.117679663002491\n",
      "예측값 pre_y => tensor([[10.8335],\n",
      "        [-3.4922],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2845],\n",
      "        [-0.1749],\n",
      "        [ 3.9072]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0295],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9864],\n",
      "        [0.4564],\n",
      "        [0.9803]], grad_fn=<SigmoidBackward0>)\n",
      "[22] Loss => 0.11765272170305252\n",
      "예측값 pre_y => tensor([[10.8368],\n",
      "        [-3.4933],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2869],\n",
      "        [-0.1752],\n",
      "        [ 3.9091]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0295],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9864],\n",
      "        [0.4563],\n",
      "        [0.9803]], grad_fn=<SigmoidBackward0>)\n",
      "[23] Loss => 0.11762581020593643\n",
      "예측값 pre_y => tensor([[10.8401],\n",
      "        [-3.4944],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2894],\n",
      "        [-0.1755],\n",
      "        [ 3.9110]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0295],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9865],\n",
      "        [0.4562],\n",
      "        [0.9804]], grad_fn=<SigmoidBackward0>)\n",
      "[24] Loss => 0.1175989955663681\n",
      "예측값 pre_y => tensor([[10.8434],\n",
      "        [-3.4954],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2919],\n",
      "        [-0.1759],\n",
      "        [ 3.9129]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0294],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9865],\n",
      "        [0.4561],\n",
      "        [0.9804]], grad_fn=<SigmoidBackward0>)\n",
      "[25] Loss => 0.11757221817970276\n",
      "예측값 pre_y => tensor([[10.8466],\n",
      "        [-3.4965],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2944],\n",
      "        [-0.1762],\n",
      "        [ 3.9148]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0294],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9865],\n",
      "        [0.4561],\n",
      "        [0.9804]], grad_fn=<SigmoidBackward0>)\n",
      "[26] Loss => 0.11754553765058517\n",
      "예측값 pre_y => tensor([[10.8499],\n",
      "        [-3.4975],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2968],\n",
      "        [-0.1765],\n",
      "        [ 3.9166]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0294],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9866],\n",
      "        [0.4560],\n",
      "        [0.9805]], grad_fn=<SigmoidBackward0>)\n",
      "[27] Loss => 0.11751890927553177\n",
      "예측값 pre_y => tensor([[10.8531],\n",
      "        [-3.4986],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.2993],\n",
      "        [-0.1769],\n",
      "        [ 3.9185]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0294],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9866],\n",
      "        [0.4559],\n",
      "        [0.9805]], grad_fn=<SigmoidBackward0>)\n",
      "[28] Loss => 0.11749234795570374\n",
      "예측값 pre_y => tensor([[10.8563],\n",
      "        [-3.4996],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.3018],\n",
      "        [-0.1772],\n",
      "        [ 3.9204]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0293],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9866],\n",
      "        [0.4558],\n",
      "        [0.9806]], grad_fn=<SigmoidBackward0>)\n",
      "[29] Loss => 0.11746585369110107\n",
      "예측값 pre_y => tensor([[10.8596],\n",
      "        [-3.5007],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.3042],\n",
      "        [-0.1776],\n",
      "        [ 3.9222]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0293],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9867],\n",
      "        [0.4557],\n",
      "        [0.9806]], grad_fn=<SigmoidBackward0>)\n",
      "[30] Loss => 0.1174393892288208\n",
      "예측값 pre_y => tensor([[10.8628],\n",
      "        [-3.5017],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.3067],\n",
      "        [-0.1779],\n",
      "        [ 3.9241]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0293],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9867],\n",
      "        [0.4556],\n",
      "        [0.9806]], grad_fn=<SigmoidBackward0>)\n",
      "[31] Loss => 0.11741302162408829\n",
      "예측값 pre_y => tensor([[10.8660],\n",
      "        [-3.5027],\n",
      "        [ 1.8114],\n",
      "        ...,\n",
      "        [ 4.3091],\n",
      "        [-0.1782],\n",
      "        [ 3.9259]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0292],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9867],\n",
      "        [0.4556],\n",
      "        [0.9807]], grad_fn=<SigmoidBackward0>)\n",
      "[32] Loss => 0.11738670617341995\n",
      "예측값 pre_y => tensor([[10.8692],\n",
      "        [-3.5038],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 4.3116],\n",
      "        [-0.1786],\n",
      "        [ 3.9278]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0292],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9868],\n",
      "        [0.4555],\n",
      "        [0.9807]], grad_fn=<SigmoidBackward0>)\n",
      "[33] Loss => 0.11736048012971878\n",
      "예측값 pre_y => tensor([[10.8724],\n",
      "        [-3.5048],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 4.3140],\n",
      "        [-0.1789],\n",
      "        [ 3.9296]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0292],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9868],\n",
      "        [0.4554],\n",
      "        [0.9807]], grad_fn=<SigmoidBackward0>)\n",
      "[34] Loss => 0.1173342913389206\n",
      "예측값 pre_y => tensor([[10.8755],\n",
      "        [-3.5058],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 4.3164],\n",
      "        [-0.1792],\n",
      "        [ 3.9314]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0291],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9868],\n",
      "        [0.4553],\n",
      "        [0.9808]], grad_fn=<SigmoidBackward0>)\n",
      "[35] Loss => 0.11730813980102539\n",
      "예측값 pre_y => tensor([[10.8787],\n",
      "        [-3.5068],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 4.3189],\n",
      "        [-0.1796],\n",
      "        [ 3.9333]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0291],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9869],\n",
      "        [0.4552],\n",
      "        [0.9808]], grad_fn=<SigmoidBackward0>)\n",
      "[36] Loss => 0.11728210002183914\n",
      "예측값 pre_y => tensor([[10.8818],\n",
      "        [-3.5078],\n",
      "        [ 1.8112],\n",
      "        ...,\n",
      "        [ 4.3213],\n",
      "        [-0.1799],\n",
      "        [ 3.9351]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0291],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9869],\n",
      "        [0.4551],\n",
      "        [0.9808]], grad_fn=<SigmoidBackward0>)\n",
      "[37] Loss => 0.11725609004497528\n",
      "예측값 pre_y => tensor([[10.8850],\n",
      "        [-3.5088],\n",
      "        [ 1.8112],\n",
      "        ...,\n",
      "        [ 4.3237],\n",
      "        [-0.1802],\n",
      "        [ 3.9369]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0291],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9869],\n",
      "        [0.4551],\n",
      "        [0.9809]], grad_fn=<SigmoidBackward0>)\n",
      "[38] Loss => 0.11723016202449799\n",
      "예측값 pre_y => tensor([[10.8881],\n",
      "        [-3.5098],\n",
      "        [ 1.8111],\n",
      "        ...,\n",
      "        [ 4.3261],\n",
      "        [-0.1806],\n",
      "        [ 3.9388]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0290],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9870],\n",
      "        [0.4550],\n",
      "        [0.9809]], grad_fn=<SigmoidBackward0>)\n",
      "[39] Loss => 0.11720427125692368\n",
      "예측값 pre_y => tensor([[10.8912],\n",
      "        [-3.5108],\n",
      "        [ 1.8111],\n",
      "        ...,\n",
      "        [ 4.3286],\n",
      "        [-0.1809],\n",
      "        [ 3.9406]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0290],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9870],\n",
      "        [0.4549],\n",
      "        [0.9809]], grad_fn=<SigmoidBackward0>)\n",
      "[40] Loss => 0.11717844754457474\n",
      "예측값 pre_y => tensor([[10.8944],\n",
      "        [-3.5118],\n",
      "        [ 1.8110],\n",
      "        ...,\n",
      "        [ 4.3310],\n",
      "        [-0.1813],\n",
      "        [ 3.9424]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0290],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9870],\n",
      "        [0.4548],\n",
      "        [0.9810]], grad_fn=<SigmoidBackward0>)\n",
      "[41] Loss => 0.11715269833803177\n",
      "예측값 pre_y => tensor([[10.8975],\n",
      "        [-3.5127],\n",
      "        [ 1.8110],\n",
      "        ...,\n",
      "        [ 4.3334],\n",
      "        [-0.1816],\n",
      "        [ 3.9442]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0290],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9870],\n",
      "        [0.4547],\n",
      "        [0.9810]], grad_fn=<SigmoidBackward0>)\n",
      "[42] Loss => 0.11712700128555298\n",
      "예측값 pre_y => tensor([[10.9006],\n",
      "        [-3.5137],\n",
      "        [ 1.8109],\n",
      "        ...,\n",
      "        [ 4.3358],\n",
      "        [-0.1819],\n",
      "        [ 3.9460]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0289],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9871],\n",
      "        [0.4546],\n",
      "        [0.9810]], grad_fn=<SigmoidBackward0>)\n",
      "[43] Loss => 0.11710134148597717\n",
      "예측값 pre_y => tensor([[10.9037],\n",
      "        [-3.5147],\n",
      "        [ 1.8109],\n",
      "        ...,\n",
      "        [ 4.3382],\n",
      "        [-0.1823],\n",
      "        [ 3.9478]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0289],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9871],\n",
      "        [0.4546],\n",
      "        [0.9811]], grad_fn=<SigmoidBackward0>)\n",
      "[44] Loss => 0.11707577854394913\n",
      "예측값 pre_y => tensor([[10.9067],\n",
      "        [-3.5157],\n",
      "        [ 1.8108],\n",
      "        ...,\n",
      "        [ 4.3406],\n",
      "        [-0.1826],\n",
      "        [ 3.9496]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0289],\n",
      "        [0.8595],\n",
      "        ...,\n",
      "        [0.9871],\n",
      "        [0.4545],\n",
      "        [0.9811]], grad_fn=<SigmoidBackward0>)\n",
      "[45] Loss => 0.11705025285482407\n",
      "예측값 pre_y => tensor([[10.9098],\n",
      "        [-3.5166],\n",
      "        [ 1.8107],\n",
      "        ...,\n",
      "        [ 4.3430],\n",
      "        [-0.1829],\n",
      "        [ 3.9514]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0288],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9872],\n",
      "        [0.4544],\n",
      "        [0.9811]], grad_fn=<SigmoidBackward0>)\n",
      "[46] Loss => 0.11702482402324677\n",
      "예측값 pre_y => tensor([[10.9129],\n",
      "        [-3.5176],\n",
      "        [ 1.8106],\n",
      "        ...,\n",
      "        [ 4.3454],\n",
      "        [-0.1833],\n",
      "        [ 3.9532]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0288],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9872],\n",
      "        [0.4543],\n",
      "        [0.9812]], grad_fn=<SigmoidBackward0>)\n",
      "[47] Loss => 0.11699939519166946\n",
      "예측값 pre_y => tensor([[10.9159],\n",
      "        [-3.5185],\n",
      "        [ 1.8106],\n",
      "        ...,\n",
      "        [ 4.3477],\n",
      "        [-0.1836],\n",
      "        [ 3.9550]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0288],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9872],\n",
      "        [0.4542],\n",
      "        [0.9812]], grad_fn=<SigmoidBackward0>)\n",
      "[48] Loss => 0.11697404086589813\n",
      "예측값 pre_y => tensor([[10.9190],\n",
      "        [-3.5195],\n",
      "        [ 1.8105],\n",
      "        ...,\n",
      "        [ 4.3501],\n",
      "        [-0.1839],\n",
      "        [ 3.9568]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0288],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9873],\n",
      "        [0.4541],\n",
      "        [0.9812]], grad_fn=<SigmoidBackward0>)\n",
      "[49] Loss => 0.11694877594709396\n",
      "예측값 pre_y => tensor([[10.9220],\n",
      "        [-3.5204],\n",
      "        [ 1.8104],\n",
      "        ...,\n",
      "        [ 4.3525],\n",
      "        [-0.1843],\n",
      "        [ 3.9585]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0287],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9873],\n",
      "        [0.4541],\n",
      "        [0.9813]], grad_fn=<SigmoidBackward0>)\n",
      "[50] Loss => 0.11692352592945099\n",
      "예측값 pre_y => tensor([[10.9251],\n",
      "        [-3.5214],\n",
      "        [ 1.8103],\n",
      "        ...,\n",
      "        [ 4.3549],\n",
      "        [-0.1846],\n",
      "        [ 3.9603]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0287],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9873],\n",
      "        [0.4540],\n",
      "        [0.9813]], grad_fn=<SigmoidBackward0>)\n",
      "[51] Loss => 0.11689834296703339\n",
      "예측값 pre_y => tensor([[10.9281],\n",
      "        [-3.5223],\n",
      "        [ 1.8102],\n",
      "        ...,\n",
      "        [ 4.3573],\n",
      "        [-0.1849],\n",
      "        [ 3.9621]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0287],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9873],\n",
      "        [0.4539],\n",
      "        [0.9813]], grad_fn=<SigmoidBackward0>)\n",
      "[52] Loss => 0.11687318980693817\n",
      "예측값 pre_y => tensor([[10.9311],\n",
      "        [-3.5233],\n",
      "        [ 1.8101],\n",
      "        ...,\n",
      "        [ 4.3596],\n",
      "        [-0.1853],\n",
      "        [ 3.9639]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0287],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9874],\n",
      "        [0.4538],\n",
      "        [0.9814]], grad_fn=<SigmoidBackward0>)\n",
      "[53] Loss => 0.1168481707572937\n",
      "예측값 pre_y => tensor([[10.9341],\n",
      "        [-3.5242],\n",
      "        [ 1.8100],\n",
      "        ...,\n",
      "        [ 4.3620],\n",
      "        [-0.1856],\n",
      "        [ 3.9656]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0286],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9874],\n",
      "        [0.4537],\n",
      "        [0.9814]], grad_fn=<SigmoidBackward0>)\n",
      "[54] Loss => 0.11682314425706863\n",
      "예측값 pre_y => tensor([[10.9371],\n",
      "        [-3.5251],\n",
      "        [ 1.8099],\n",
      "        ...,\n",
      "        [ 4.3643],\n",
      "        [-0.1859],\n",
      "        [ 3.9674]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0286],\n",
      "        [0.8594],\n",
      "        ...,\n",
      "        [0.9874],\n",
      "        [0.4536],\n",
      "        [0.9814]], grad_fn=<SigmoidBackward0>)\n",
      "[55] Loss => 0.11679817736148834\n",
      "예측값 pre_y => tensor([[10.9401],\n",
      "        [-3.5260],\n",
      "        [ 1.8098],\n",
      "        ...,\n",
      "        [ 4.3667],\n",
      "        [-0.1863],\n",
      "        [ 3.9691]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0286],\n",
      "        [0.8593],\n",
      "        ...,\n",
      "        [0.9875],\n",
      "        [0.4536],\n",
      "        [0.9815]], grad_fn=<SigmoidBackward0>)\n",
      "[56] Loss => 0.11677331477403641\n",
      "예측값 pre_y => tensor([[10.9431],\n",
      "        [-3.5270],\n",
      "        [ 1.8097],\n",
      "        ...,\n",
      "        [ 4.3691],\n",
      "        [-0.1866],\n",
      "        [ 3.9709]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0286],\n",
      "        [0.8593],\n",
      "        ...,\n",
      "        [0.9875],\n",
      "        [0.4535],\n",
      "        [0.9815]], grad_fn=<SigmoidBackward0>)\n",
      "[57] Loss => 0.11674845963716507\n",
      "예측값 pre_y => tensor([[10.9460],\n",
      "        [-3.5279],\n",
      "        [ 1.8096],\n",
      "        ...,\n",
      "        [ 4.3714],\n",
      "        [-0.1869],\n",
      "        [ 3.9727]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0285],\n",
      "        [0.8593],\n",
      "        ...,\n",
      "        [0.9875],\n",
      "        [0.4534],\n",
      "        [0.9815]], grad_fn=<SigmoidBackward0>)\n",
      "[58] Loss => 0.11672366410493851\n",
      "예측값 pre_y => tensor([[10.9490],\n",
      "        [-3.5288],\n",
      "        [ 1.8095],\n",
      "        ...,\n",
      "        [ 4.3738],\n",
      "        [-0.1873],\n",
      "        [ 3.9744]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0285],\n",
      "        [0.8593],\n",
      "        ...,\n",
      "        [0.9876],\n",
      "        [0.4533],\n",
      "        [0.9816]], grad_fn=<SigmoidBackward0>)\n",
      "[59] Loss => 0.11669895797967911\n",
      "예측값 pre_y => tensor([[10.9520],\n",
      "        [-3.5297],\n",
      "        [ 1.8094],\n",
      "        ...,\n",
      "        [ 4.3761],\n",
      "        [-0.1876],\n",
      "        [ 3.9761]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0285],\n",
      "        [0.8593],\n",
      "        ...,\n",
      "        [0.9876],\n",
      "        [0.4532],\n",
      "        [0.9816]], grad_fn=<SigmoidBackward0>)\n",
      "[60] Loss => 0.1166742742061615\n",
      "예측값 pre_y => tensor([[10.9549],\n",
      "        [-3.5306],\n",
      "        [ 1.8093],\n",
      "        ...,\n",
      "        [ 4.3784],\n",
      "        [-0.1879],\n",
      "        [ 3.9779]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0285],\n",
      "        [0.8593],\n",
      "        ...,\n",
      "        [0.9876],\n",
      "        [0.4532],\n",
      "        [0.9816]], grad_fn=<SigmoidBackward0>)\n",
      "[61] Loss => 0.11664962768554688\n",
      "예측값 pre_y => tensor([[10.9579],\n",
      "        [-3.5315],\n",
      "        [ 1.8092],\n",
      "        ...,\n",
      "        [ 4.3808],\n",
      "        [-0.1883],\n",
      "        [ 3.9796]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0284],\n",
      "        [0.8593],\n",
      "        ...,\n",
      "        [0.9876],\n",
      "        [0.4531],\n",
      "        [0.9817]], grad_fn=<SigmoidBackward0>)\n",
      "[62] Loss => 0.11662505567073822\n",
      "예측값 pre_y => tensor([[10.9608],\n",
      "        [-3.5324],\n",
      "        [ 1.8090],\n",
      "        ...,\n",
      "        [ 4.3831],\n",
      "        [-0.1886],\n",
      "        [ 3.9814]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0284],\n",
      "        [0.8592],\n",
      "        ...,\n",
      "        [0.9877],\n",
      "        [0.4530],\n",
      "        [0.9817]], grad_fn=<SigmoidBackward0>)\n",
      "[63] Loss => 0.11660055071115494\n",
      "예측값 pre_y => tensor([[10.9637],\n",
      "        [-3.5333],\n",
      "        [ 1.8089],\n",
      "        ...,\n",
      "        [ 4.3854],\n",
      "        [-0.1889],\n",
      "        [ 3.9831]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0284],\n",
      "        [0.8592],\n",
      "        ...,\n",
      "        [0.9877],\n",
      "        [0.4529],\n",
      "        [0.9817]], grad_fn=<SigmoidBackward0>)\n",
      "[64] Loss => 0.11657609790563583\n",
      "예측값 pre_y => tensor([[10.9667],\n",
      "        [-3.5342],\n",
      "        [ 1.8088],\n",
      "        ...,\n",
      "        [ 4.3878],\n",
      "        [-0.1893],\n",
      "        [ 3.9848]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0284],\n",
      "        [0.8592],\n",
      "        ...,\n",
      "        [0.9877],\n",
      "        [0.4528],\n",
      "        [0.9817]], grad_fn=<SigmoidBackward0>)\n",
      "[65] Loss => 0.11655167490243912\n",
      "예측값 pre_y => tensor([[10.9696],\n",
      "        [-3.5351],\n",
      "        [ 1.8086],\n",
      "        ...,\n",
      "        [ 4.3901],\n",
      "        [-0.1896],\n",
      "        [ 3.9865]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0283],\n",
      "        [0.8592],\n",
      "        ...,\n",
      "        [0.9878],\n",
      "        [0.4527],\n",
      "        [0.9818]], grad_fn=<SigmoidBackward0>)\n",
      "[66] Loss => 0.11652730405330658\n",
      "예측값 pre_y => tensor([[10.9725],\n",
      "        [-3.5360],\n",
      "        [ 1.8085],\n",
      "        ...,\n",
      "        [ 4.3924],\n",
      "        [-0.1899],\n",
      "        [ 3.9883]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0283],\n",
      "        [0.8592],\n",
      "        ...,\n",
      "        [0.9878],\n",
      "        [0.4527],\n",
      "        [0.9818]], grad_fn=<SigmoidBackward0>)\n",
      "[67] Loss => 0.1165030300617218\n",
      "예측값 pre_y => tensor([[10.9754],\n",
      "        [-3.5368],\n",
      "        [ 1.8084],\n",
      "        ...,\n",
      "        [ 4.3947],\n",
      "        [-0.1903],\n",
      "        [ 3.9900]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0283],\n",
      "        [0.8592],\n",
      "        ...,\n",
      "        [0.9878],\n",
      "        [0.4526],\n",
      "        [0.9818]], grad_fn=<SigmoidBackward0>)\n",
      "[68] Loss => 0.11647874861955643\n",
      "예측값 pre_y => tensor([[10.9783],\n",
      "        [-3.5377],\n",
      "        [ 1.8082],\n",
      "        ...,\n",
      "        [ 4.3970],\n",
      "        [-0.1906],\n",
      "        [ 3.9917]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0283],\n",
      "        [0.8591],\n",
      "        ...,\n",
      "        [0.9878],\n",
      "        [0.4525],\n",
      "        [0.9819]], grad_fn=<SigmoidBackward0>)\n",
      "[69] Loss => 0.11645455658435822\n",
      "예측값 pre_y => tensor([[10.9811],\n",
      "        [-3.5386],\n",
      "        [ 1.8081],\n",
      "        ...,\n",
      "        [ 4.3993],\n",
      "        [-0.1909],\n",
      "        [ 3.9934]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0282],\n",
      "        [0.8591],\n",
      "        ...,\n",
      "        [0.9879],\n",
      "        [0.4524],\n",
      "        [0.9819]], grad_fn=<SigmoidBackward0>)\n",
      "[70] Loss => 0.1164303869009018\n",
      "예측값 pre_y => tensor([[10.9840],\n",
      "        [-3.5395],\n",
      "        [ 1.8079],\n",
      "        ...,\n",
      "        [ 4.4016],\n",
      "        [-0.1913],\n",
      "        [ 3.9951]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0282],\n",
      "        [0.8591],\n",
      "        ...,\n",
      "        [0.9879],\n",
      "        [0.4523],\n",
      "        [0.9819]], grad_fn=<SigmoidBackward0>)\n",
      "[71] Loss => 0.11640632152557373\n",
      "예측값 pre_y => tensor([[10.9869],\n",
      "        [-3.5403],\n",
      "        [ 1.8078],\n",
      "        ...,\n",
      "        [ 4.4039],\n",
      "        [-0.1916],\n",
      "        [ 3.9968]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0282],\n",
      "        [0.8591],\n",
      "        ...,\n",
      "        [0.9879],\n",
      "        [0.4522],\n",
      "        [0.9820]], grad_fn=<SigmoidBackward0>)\n",
      "[72] Loss => 0.11638227850198746\n",
      "예측값 pre_y => tensor([[10.9898],\n",
      "        [-3.5412],\n",
      "        [ 1.8076],\n",
      "        ...,\n",
      "        [ 4.4062],\n",
      "        [-0.1919],\n",
      "        [ 3.9985]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0282],\n",
      "        [0.8591],\n",
      "        ...,\n",
      "        [0.9879],\n",
      "        [0.4522],\n",
      "        [0.9820]], grad_fn=<SigmoidBackward0>)\n",
      "[73] Loss => 0.11635826528072357\n",
      "예측값 pre_y => tensor([[10.9926],\n",
      "        [-3.5421],\n",
      "        [ 1.8075],\n",
      "        ...,\n",
      "        [ 4.4085],\n",
      "        [-0.1923],\n",
      "        [ 4.0002]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0281],\n",
      "        [0.8591],\n",
      "        ...,\n",
      "        [0.9880],\n",
      "        [0.4521],\n",
      "        [0.9820]], grad_fn=<SigmoidBackward0>)\n",
      "[74] Loss => 0.11633432656526566\n",
      "예측값 pre_y => tensor([[10.9955],\n",
      "        [-3.5429],\n",
      "        [ 1.8073],\n",
      "        ...,\n",
      "        [ 4.4108],\n",
      "        [-0.1926],\n",
      "        [ 4.0019]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0281],\n",
      "        [0.8590],\n",
      "        ...,\n",
      "        [0.9880],\n",
      "        [0.4520],\n",
      "        [0.9820]], grad_fn=<SigmoidBackward0>)\n",
      "[75] Loss => 0.11631045490503311\n",
      "예측값 pre_y => tensor([[10.9983],\n",
      "        [-3.5438],\n",
      "        [ 1.8071],\n",
      "        ...,\n",
      "        [ 4.4131],\n",
      "        [-0.1929],\n",
      "        [ 4.0036]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0281],\n",
      "        [0.8590],\n",
      "        ...,\n",
      "        [0.9880],\n",
      "        [0.4519],\n",
      "        [0.9821]], grad_fn=<SigmoidBackward0>)\n",
      "[76] Loss => 0.11628660559654236\n",
      "예측값 pre_y => tensor([[11.0011],\n",
      "        [-3.5446],\n",
      "        [ 1.8070],\n",
      "        ...,\n",
      "        [ 4.4154],\n",
      "        [-0.1933],\n",
      "        [ 4.0053]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0281],\n",
      "        [0.8590],\n",
      "        ...,\n",
      "        [0.9881],\n",
      "        [0.4518],\n",
      "        [0.9821]], grad_fn=<SigmoidBackward0>)\n",
      "[77] Loss => 0.11626279354095459\n",
      "예측값 pre_y => tensor([[11.0040],\n",
      "        [-3.5455],\n",
      "        [ 1.8068],\n",
      "        ...,\n",
      "        [ 4.4177],\n",
      "        [-0.1936],\n",
      "        [ 4.0070]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0280],\n",
      "        [0.8590],\n",
      "        ...,\n",
      "        [0.9881],\n",
      "        [0.4517],\n",
      "        [0.9821]], grad_fn=<SigmoidBackward0>)\n",
      "[78] Loss => 0.1162390485405922\n",
      "예측값 pre_y => tensor([[11.0068],\n",
      "        [-3.5463],\n",
      "        [ 1.8066],\n",
      "        ...,\n",
      "        [ 4.4200],\n",
      "        [-0.1939],\n",
      "        [ 4.0087]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0280],\n",
      "        [0.8590],\n",
      "        ...,\n",
      "        [0.9881],\n",
      "        [0.4517],\n",
      "        [0.9822]], grad_fn=<SigmoidBackward0>)\n",
      "[79] Loss => 0.11621533334255219\n",
      "예측값 pre_y => tensor([[11.0096],\n",
      "        [-3.5472],\n",
      "        [ 1.8065],\n",
      "        ...,\n",
      "        [ 4.4222],\n",
      "        [-0.1943],\n",
      "        [ 4.0103]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0280],\n",
      "        [0.8589],\n",
      "        ...,\n",
      "        [0.9881],\n",
      "        [0.4516],\n",
      "        [0.9822]], grad_fn=<SigmoidBackward0>)\n",
      "[80] Loss => 0.11619172990322113\n",
      "예측값 pre_y => tensor([[11.0124],\n",
      "        [-3.5480],\n",
      "        [ 1.8063],\n",
      "        ...,\n",
      "        [ 4.4245],\n",
      "        [-0.1946],\n",
      "        [ 4.0120]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0280],\n",
      "        [0.8589],\n",
      "        ...,\n",
      "        [0.9882],\n",
      "        [0.4515],\n",
      "        [0.9822]], grad_fn=<SigmoidBackward0>)\n",
      "[81] Loss => 0.11616813391447067\n",
      "예측값 pre_y => tensor([[11.0152],\n",
      "        [-3.5488],\n",
      "        [ 1.8061],\n",
      "        ...,\n",
      "        [ 4.4268],\n",
      "        [-0.1949],\n",
      "        [ 4.0137]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0280],\n",
      "        [0.8589],\n",
      "        ...,\n",
      "        [0.9882],\n",
      "        [0.4514],\n",
      "        [0.9823]], grad_fn=<SigmoidBackward0>)\n",
      "[82] Loss => 0.1161445751786232\n",
      "예측값 pre_y => tensor([[11.0180],\n",
      "        [-3.5497],\n",
      "        [ 1.8059],\n",
      "        ...,\n",
      "        [ 4.4290],\n",
      "        [-0.1953],\n",
      "        [ 4.0153]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0279],\n",
      "        [0.8589],\n",
      "        ...,\n",
      "        [0.9882],\n",
      "        [0.4513],\n",
      "        [0.9823]], grad_fn=<SigmoidBackward0>)\n",
      "[83] Loss => 0.11612106114625931\n",
      "예측값 pre_y => tensor([[11.0208],\n",
      "        [-3.5505],\n",
      "        [ 1.8057],\n",
      "        ...,\n",
      "        [ 4.4313],\n",
      "        [-0.1956],\n",
      "        [ 4.0170]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0279],\n",
      "        [0.8588],\n",
      "        ...,\n",
      "        [0.9882],\n",
      "        [0.4513],\n",
      "        [0.9823]], grad_fn=<SigmoidBackward0>)\n",
      "[84] Loss => 0.11609760671854019\n",
      "예측값 pre_y => tensor([[11.0236],\n",
      "        [-3.5513],\n",
      "        [ 1.8056],\n",
      "        ...,\n",
      "        [ 4.4336],\n",
      "        [-0.1959],\n",
      "        [ 4.0187]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0279],\n",
      "        [0.8588],\n",
      "        ...,\n",
      "        [0.9883],\n",
      "        [0.4512],\n",
      "        [0.9823]], grad_fn=<SigmoidBackward0>)\n",
      "[85] Loss => 0.11607423424720764\n",
      "예측값 pre_y => tensor([[11.0264],\n",
      "        [-3.5522],\n",
      "        [ 1.8054],\n",
      "        ...,\n",
      "        [ 4.4358],\n",
      "        [-0.1963],\n",
      "        [ 4.0203]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0279],\n",
      "        [0.8588],\n",
      "        ...,\n",
      "        [0.9883],\n",
      "        [0.4511],\n",
      "        [0.9824]], grad_fn=<SigmoidBackward0>)\n",
      "[86] Loss => 0.11605087667703629\n",
      "예측값 pre_y => tensor([[11.0291],\n",
      "        [-3.5530],\n",
      "        [ 1.8052],\n",
      "        ...,\n",
      "        [ 4.4381],\n",
      "        [-0.1966],\n",
      "        [ 4.0220]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0278],\n",
      "        [0.8588],\n",
      "        ...,\n",
      "        [0.9883],\n",
      "        [0.4510],\n",
      "        [0.9824]], grad_fn=<SigmoidBackward0>)\n",
      "[87] Loss => 0.11602757126092911\n",
      "예측값 pre_y => tensor([[11.0319],\n",
      "        [-3.5538],\n",
      "        [ 1.8050],\n",
      "        ...,\n",
      "        [ 4.4403],\n",
      "        [-0.1969],\n",
      "        [ 4.0237]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0278],\n",
      "        [0.8588],\n",
      "        ...,\n",
      "        [0.9883],\n",
      "        [0.4509],\n",
      "        [0.9824]], grad_fn=<SigmoidBackward0>)\n",
      "[88] Loss => 0.11600429564714432\n",
      "예측값 pre_y => tensor([[11.0347],\n",
      "        [-3.5546],\n",
      "        [ 1.8048],\n",
      "        ...,\n",
      "        [ 4.4426],\n",
      "        [-0.1973],\n",
      "        [ 4.0253]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0278],\n",
      "        [0.8587],\n",
      "        ...,\n",
      "        [0.9884],\n",
      "        [0.4508],\n",
      "        [0.9825]], grad_fn=<SigmoidBackward0>)\n",
      "[89] Loss => 0.1159810721874237\n",
      "예측값 pre_y => tensor([[11.0374],\n",
      "        [-3.5554],\n",
      "        [ 1.8046],\n",
      "        ...,\n",
      "        [ 4.4448],\n",
      "        [-0.1976],\n",
      "        [ 4.0270]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0278],\n",
      "        [0.8587],\n",
      "        ...,\n",
      "        [0.9884],\n",
      "        [0.4508],\n",
      "        [0.9825]], grad_fn=<SigmoidBackward0>)\n",
      "[90] Loss => 0.11595790833234787\n",
      "예측값 pre_y => tensor([[11.0401],\n",
      "        [-3.5563],\n",
      "        [ 1.8044],\n",
      "        ...,\n",
      "        [ 4.4470],\n",
      "        [-0.1979],\n",
      "        [ 4.0286]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0278],\n",
      "        [0.8587],\n",
      "        ...,\n",
      "        [0.9884],\n",
      "        [0.4507],\n",
      "        [0.9825]], grad_fn=<SigmoidBackward0>)\n",
      "[91] Loss => 0.1159348115324974\n",
      "예측값 pre_y => tensor([[11.0429],\n",
      "        [-3.5571],\n",
      "        [ 1.8042],\n",
      "        ...,\n",
      "        [ 4.4493],\n",
      "        [-0.1983],\n",
      "        [ 4.0302]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0277],\n",
      "        [0.8587],\n",
      "        ...,\n",
      "        [0.9884],\n",
      "        [0.4506],\n",
      "        [0.9825]], grad_fn=<SigmoidBackward0>)\n",
      "[92] Loss => 0.11591173708438873\n",
      "예측값 pre_y => tensor([[11.0456],\n",
      "        [-3.5579],\n",
      "        [ 1.8040],\n",
      "        ...,\n",
      "        [ 4.4515],\n",
      "        [-0.1986],\n",
      "        [ 4.0319]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0277],\n",
      "        [0.8586],\n",
      "        ...,\n",
      "        [0.9885],\n",
      "        [0.4505],\n",
      "        [0.9826]], grad_fn=<SigmoidBackward0>)\n",
      "[93] Loss => 0.11588872224092484\n",
      "예측값 pre_y => tensor([[11.0484],\n",
      "        [-3.5587],\n",
      "        [ 1.8037],\n",
      "        ...,\n",
      "        [ 4.4537],\n",
      "        [-0.1989],\n",
      "        [ 4.0335]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0277],\n",
      "        [0.8586],\n",
      "        ...,\n",
      "        [0.9885],\n",
      "        [0.4504],\n",
      "        [0.9826]], grad_fn=<SigmoidBackward0>)\n",
      "[94] Loss => 0.11586572974920273\n",
      "예측값 pre_y => tensor([[11.0511],\n",
      "        [-3.5595],\n",
      "        [ 1.8035],\n",
      "        ...,\n",
      "        [ 4.4560],\n",
      "        [-0.1992],\n",
      "        [ 4.0352]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0277],\n",
      "        [0.8586],\n",
      "        ...,\n",
      "        [0.9885],\n",
      "        [0.4504],\n",
      "        [0.9826]], grad_fn=<SigmoidBackward0>)\n",
      "[95] Loss => 0.1158427968621254\n",
      "예측값 pre_y => tensor([[11.0538],\n",
      "        [-3.5603],\n",
      "        [ 1.8033],\n",
      "        ...,\n",
      "        [ 4.4582],\n",
      "        [-0.1996],\n",
      "        [ 4.0368]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0276],\n",
      "        [0.8586],\n",
      "        ...,\n",
      "        [0.9885],\n",
      "        [0.4503],\n",
      "        [0.9827]], grad_fn=<SigmoidBackward0>)\n",
      "[96] Loss => 0.11581990867853165\n",
      "예측값 pre_y => tensor([[11.0565],\n",
      "        [-3.5611],\n",
      "        [ 1.8031],\n",
      "        ...,\n",
      "        [ 4.4604],\n",
      "        [-0.1999],\n",
      "        [ 4.0384]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0276],\n",
      "        [0.8585],\n",
      "        ...,\n",
      "        [0.9886],\n",
      "        [0.4502],\n",
      "        [0.9827]], grad_fn=<SigmoidBackward0>)\n",
      "[97] Loss => 0.11579710245132446\n",
      "예측값 pre_y => tensor([[11.0592],\n",
      "        [-3.5619],\n",
      "        [ 1.8029],\n",
      "        ...,\n",
      "        [ 4.4626],\n",
      "        [-0.2002],\n",
      "        [ 4.0400]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0276],\n",
      "        [0.8585],\n",
      "        ...,\n",
      "        [0.9886],\n",
      "        [0.4501],\n",
      "        [0.9827]], grad_fn=<SigmoidBackward0>)\n",
      "[98] Loss => 0.11577430367469788\n",
      "예측값 pre_y => tensor([[11.0619],\n",
      "        [-3.5627],\n",
      "        [ 1.8026],\n",
      "        ...,\n",
      "        [ 4.4648],\n",
      "        [-0.2006],\n",
      "        [ 4.0417]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0276],\n",
      "        [0.8585],\n",
      "        ...,\n",
      "        [0.9886],\n",
      "        [0.4500],\n",
      "        [0.9827]], grad_fn=<SigmoidBackward0>)\n",
      "[99] Loss => 0.11575153470039368\n",
      "예측값 pre_y => tensor([[11.0646],\n",
      "        [-3.5635],\n",
      "        [ 1.8024],\n",
      "        ...,\n",
      "        [ 4.4670],\n",
      "        [-0.2009],\n",
      "        [ 4.0433]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0276],\n",
      "        [0.8584],\n",
      "        ...,\n",
      "        [0.9886],\n",
      "        [0.4499],\n",
      "        [0.9828]], grad_fn=<SigmoidBackward0>)\n",
      "[100] Loss => 0.11572884023189545\n",
      "예측값 pre_y => tensor([[11.0673],\n",
      "        [-3.5643],\n",
      "        [ 1.8022],\n",
      "        ...,\n",
      "        [ 4.4693],\n",
      "        [-0.2012],\n",
      "        [ 4.0449]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0275],\n",
      "        [0.8584],\n",
      "        ...,\n",
      "        [0.9887],\n",
      "        [0.4499],\n",
      "        [0.9828]], grad_fn=<SigmoidBackward0>)\n",
      "[101] Loss => 0.1157061830163002\n",
      "예측값 pre_y => tensor([[11.0700],\n",
      "        [-3.5650],\n",
      "        [ 1.8020],\n",
      "        ...,\n",
      "        [ 4.4715],\n",
      "        [-0.2016],\n",
      "        [ 4.0465]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0275],\n",
      "        [0.8584],\n",
      "        ...,\n",
      "        [0.9887],\n",
      "        [0.4498],\n",
      "        [0.9828]], grad_fn=<SigmoidBackward0>)\n",
      "[102] Loss => 0.11568356305360794\n",
      "예측값 pre_y => tensor([[11.0726],\n",
      "        [-3.5658],\n",
      "        [ 1.8017],\n",
      "        ...,\n",
      "        [ 4.4737],\n",
      "        [-0.2019],\n",
      "        [ 4.0481]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0275],\n",
      "        [0.8584],\n",
      "        ...,\n",
      "        [0.9887],\n",
      "        [0.4497],\n",
      "        [0.9828]], grad_fn=<SigmoidBackward0>)\n",
      "[103] Loss => 0.11566099524497986\n",
      "예측값 pre_y => tensor([[11.0753],\n",
      "        [-3.5666],\n",
      "        [ 1.8015],\n",
      "        ...,\n",
      "        [ 4.4759],\n",
      "        [-0.2022],\n",
      "        [ 4.0497]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0275],\n",
      "        [0.8583],\n",
      "        ...,\n",
      "        [0.9887],\n",
      "        [0.4496],\n",
      "        [0.9829]], grad_fn=<SigmoidBackward0>)\n",
      "[104] Loss => 0.11563844233751297\n",
      "예측값 pre_y => tensor([[11.0780],\n",
      "        [-3.5674],\n",
      "        [ 1.8012],\n",
      "        ...,\n",
      "        [ 4.4781],\n",
      "        [-0.2026],\n",
      "        [ 4.0513]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0275],\n",
      "        [0.8583],\n",
      "        ...,\n",
      "        [0.9888],\n",
      "        [0.4495],\n",
      "        [0.9829]], grad_fn=<SigmoidBackward0>)\n",
      "[105] Loss => 0.11561601608991623\n",
      "예측값 pre_y => tensor([[11.0806],\n",
      "        [-3.5682],\n",
      "        [ 1.8010],\n",
      "        ...,\n",
      "        [ 4.4802],\n",
      "        [-0.2029],\n",
      "        [ 4.0529]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0274],\n",
      "        [0.8583],\n",
      "        ...,\n",
      "        [0.9888],\n",
      "        [0.4495],\n",
      "        [0.9829]], grad_fn=<SigmoidBackward0>)\n",
      "[106] Loss => 0.1155935674905777\n",
      "예측값 pre_y => tensor([[11.0833],\n",
      "        [-3.5689],\n",
      "        [ 1.8008],\n",
      "        ...,\n",
      "        [ 4.4824],\n",
      "        [-0.2032],\n",
      "        [ 4.0545]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0274],\n",
      "        [0.8582],\n",
      "        ...,\n",
      "        [0.9888],\n",
      "        [0.4494],\n",
      "        [0.9830]], grad_fn=<SigmoidBackward0>)\n",
      "[107] Loss => 0.11557117849588394\n",
      "예측값 pre_y => tensor([[11.0859],\n",
      "        [-3.5697],\n",
      "        [ 1.8005],\n",
      "        ...,\n",
      "        [ 4.4846],\n",
      "        [-0.2036],\n",
      "        [ 4.0561]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0274],\n",
      "        [0.8582],\n",
      "        ...,\n",
      "        [0.9888],\n",
      "        [0.4493],\n",
      "        [0.9830]], grad_fn=<SigmoidBackward0>)\n",
      "[108] Loss => 0.11554881930351257\n",
      "예측값 pre_y => tensor([[11.0886],\n",
      "        [-3.5705],\n",
      "        [ 1.8003],\n",
      "        ...,\n",
      "        [ 4.4868],\n",
      "        [-0.2039],\n",
      "        [ 4.0577]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0274],\n",
      "        [0.8582],\n",
      "        ...,\n",
      "        [0.9889],\n",
      "        [0.4492],\n",
      "        [0.9830]], grad_fn=<SigmoidBackward0>)\n",
      "[109] Loss => 0.11552651226520538\n",
      "예측값 pre_y => tensor([[11.0912],\n",
      "        [-3.5713],\n",
      "        [ 1.8000],\n",
      "        ...,\n",
      "        [ 4.4890],\n",
      "        [-0.2042],\n",
      "        [ 4.0593]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0274],\n",
      "        [0.8582],\n",
      "        ...,\n",
      "        [0.9889],\n",
      "        [0.4491],\n",
      "        [0.9830]], grad_fn=<SigmoidBackward0>)\n",
      "[110] Loss => 0.11550424993038177\n",
      "예측값 pre_y => tensor([[11.0938],\n",
      "        [-3.5720],\n",
      "        [ 1.7998],\n",
      "        ...,\n",
      "        [ 4.4912],\n",
      "        [-0.2045],\n",
      "        [ 4.0609]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0273],\n",
      "        [0.8581],\n",
      "        ...,\n",
      "        [0.9889],\n",
      "        [0.4490],\n",
      "        [0.9831]], grad_fn=<SigmoidBackward0>)\n",
      "[111] Loss => 0.11548202484846115\n",
      "예측값 pre_y => tensor([[11.0965],\n",
      "        [-3.5728],\n",
      "        [ 1.7995],\n",
      "        ...,\n",
      "        [ 4.4933],\n",
      "        [-0.2049],\n",
      "        [ 4.0625]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0273],\n",
      "        [0.8581],\n",
      "        ...,\n",
      "        [0.9889],\n",
      "        [0.4490],\n",
      "        [0.9831]], grad_fn=<SigmoidBackward0>)\n",
      "[112] Loss => 0.11545984447002411\n",
      "예측값 pre_y => tensor([[11.0991],\n",
      "        [-3.5736],\n",
      "        [ 1.7992],\n",
      "        ...,\n",
      "        [ 4.4955],\n",
      "        [-0.2052],\n",
      "        [ 4.0641]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0273],\n",
      "        [0.8581],\n",
      "        ...,\n",
      "        [0.9890],\n",
      "        [0.4489],\n",
      "        [0.9831]], grad_fn=<SigmoidBackward0>)\n",
      "[113] Loss => 0.11543770879507065\n",
      "예측값 pre_y => tensor([[11.1017],\n",
      "        [-3.5743],\n",
      "        [ 1.7990],\n",
      "        ...,\n",
      "        [ 4.4977],\n",
      "        [-0.2055],\n",
      "        [ 4.0657]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0273],\n",
      "        [0.8580],\n",
      "        ...,\n",
      "        [0.9890],\n",
      "        [0.4488],\n",
      "        [0.9831]], grad_fn=<SigmoidBackward0>)\n",
      "[114] Loss => 0.11541565507650375\n",
      "예측값 pre_y => tensor([[11.1043],\n",
      "        [-3.5751],\n",
      "        [ 1.7987],\n",
      "        ...,\n",
      "        [ 4.4998],\n",
      "        [-0.2059],\n",
      "        [ 4.0673]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0272],\n",
      "        [0.8580],\n",
      "        ...,\n",
      "        [0.9890],\n",
      "        [0.4487],\n",
      "        [0.9832]], grad_fn=<SigmoidBackward0>)\n",
      "[115] Loss => 0.11539360880851746\n",
      "예측값 pre_y => tensor([[11.1069],\n",
      "        [-3.5758],\n",
      "        [ 1.7985],\n",
      "        ...,\n",
      "        [ 4.5020],\n",
      "        [-0.2062],\n",
      "        [ 4.0688]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0272],\n",
      "        [0.8580],\n",
      "        ...,\n",
      "        [0.9890],\n",
      "        [0.4486],\n",
      "        [0.9832]], grad_fn=<SigmoidBackward0>)\n",
      "[116] Loss => 0.11537161469459534\n",
      "예측값 pre_y => tensor([[11.1095],\n",
      "        [-3.5766],\n",
      "        [ 1.7982],\n",
      "        ...,\n",
      "        [ 4.5042],\n",
      "        [-0.2065],\n",
      "        [ 4.0704]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0272],\n",
      "        [0.8579],\n",
      "        ...,\n",
      "        [0.9891],\n",
      "        [0.4486],\n",
      "        [0.9832]], grad_fn=<SigmoidBackward0>)\n",
      "[117] Loss => 0.11534964293241501\n",
      "예측값 pre_y => tensor([[11.1121],\n",
      "        [-3.5774],\n",
      "        [ 1.7979],\n",
      "        ...,\n",
      "        [ 4.5063],\n",
      "        [-0.2069],\n",
      "        [ 4.0720]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0272],\n",
      "        [0.8579],\n",
      "        ...,\n",
      "        [0.9891],\n",
      "        [0.4485],\n",
      "        [0.9832]], grad_fn=<SigmoidBackward0>)\n",
      "[118] Loss => 0.11532771587371826\n",
      "예측값 pre_y => tensor([[11.1147],\n",
      "        [-3.5781],\n",
      "        [ 1.7977],\n",
      "        ...,\n",
      "        [ 4.5085],\n",
      "        [-0.2072],\n",
      "        [ 4.0736]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0272],\n",
      "        [0.8579],\n",
      "        ...,\n",
      "        [0.9891],\n",
      "        [0.4484],\n",
      "        [0.9833]], grad_fn=<SigmoidBackward0>)\n",
      "[119] Loss => 0.1153058260679245\n",
      "예측값 pre_y => tensor([[11.1173],\n",
      "        [-3.5789],\n",
      "        [ 1.7974],\n",
      "        ...,\n",
      "        [ 4.5106],\n",
      "        [-0.2075],\n",
      "        [ 4.0751]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0271],\n",
      "        [0.8578],\n",
      "        ...,\n",
      "        [0.9891],\n",
      "        [0.4483],\n",
      "        [0.9833]], grad_fn=<SigmoidBackward0>)\n",
      "[120] Loss => 0.11528400331735611\n",
      "예측값 pre_y => tensor([[11.1199],\n",
      "        [-3.5796],\n",
      "        [ 1.7971],\n",
      "        ...,\n",
      "        [ 4.5128],\n",
      "        [-0.2078],\n",
      "        [ 4.0767]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0271],\n",
      "        [0.8578],\n",
      "        ...,\n",
      "        [0.9892],\n",
      "        [0.4482],\n",
      "        [0.9833]], grad_fn=<SigmoidBackward0>)\n",
      "[121] Loss => 0.11526221036911011\n",
      "예측값 pre_y => tensor([[11.1225],\n",
      "        [-3.5804],\n",
      "        [ 1.7968],\n",
      "        ...,\n",
      "        [ 4.5149],\n",
      "        [-0.2082],\n",
      "        [ 4.0783]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0271],\n",
      "        [0.8578],\n",
      "        ...,\n",
      "        [0.9892],\n",
      "        [0.4481],\n",
      "        [0.9833]], grad_fn=<SigmoidBackward0>)\n",
      "[122] Loss => 0.11524044722318649\n",
      "예측값 pre_y => tensor([[11.1251],\n",
      "        [-3.5811],\n",
      "        [ 1.7965],\n",
      "        ...,\n",
      "        [ 4.5171],\n",
      "        [-0.2085],\n",
      "        [ 4.0798]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0271],\n",
      "        [0.8577],\n",
      "        ...,\n",
      "        [0.9892],\n",
      "        [0.4481],\n",
      "        [0.9834]], grad_fn=<SigmoidBackward0>)\n",
      "[123] Loss => 0.11521873623132706\n",
      "예측값 pre_y => tensor([[11.1276],\n",
      "        [-3.5818],\n",
      "        [ 1.7963],\n",
      "        ...,\n",
      "        [ 4.5192],\n",
      "        [-0.2088],\n",
      "        [ 4.0814]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0271],\n",
      "        [0.8577],\n",
      "        ...,\n",
      "        [0.9892],\n",
      "        [0.4480],\n",
      "        [0.9834]], grad_fn=<SigmoidBackward0>)\n",
      "[124] Loss => 0.11519705504179001\n",
      "예측값 pre_y => tensor([[11.1302],\n",
      "        [-3.5826],\n",
      "        [ 1.7960],\n",
      "        ...,\n",
      "        [ 4.5213],\n",
      "        [-0.2092],\n",
      "        [ 4.0829]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0271],\n",
      "        [0.8577],\n",
      "        ...,\n",
      "        [0.9892],\n",
      "        [0.4479],\n",
      "        [0.9834]], grad_fn=<SigmoidBackward0>)\n",
      "[125] Loss => 0.11517544090747833\n",
      "예측값 pre_y => tensor([[11.1328],\n",
      "        [-3.5833],\n",
      "        [ 1.7957],\n",
      "        ...,\n",
      "        [ 4.5235],\n",
      "        [-0.2095],\n",
      "        [ 4.0845]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0270],\n",
      "        [0.8576],\n",
      "        ...,\n",
      "        [0.9893],\n",
      "        [0.4478],\n",
      "        [0.9834]], grad_fn=<SigmoidBackward0>)\n",
      "[126] Loss => 0.11515387147665024\n",
      "예측값 pre_y => tensor([[11.1353],\n",
      "        [-3.5841],\n",
      "        [ 1.7954],\n",
      "        ...,\n",
      "        [ 4.5256],\n",
      "        [-0.2098],\n",
      "        [ 4.0860]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0270],\n",
      "        [0.8576],\n",
      "        ...,\n",
      "        [0.9893],\n",
      "        [0.4477],\n",
      "        [0.9835]], grad_fn=<SigmoidBackward0>)\n",
      "[127] Loss => 0.11513232439756393\n",
      "예측값 pre_y => tensor([[11.1379],\n",
      "        [-3.5848],\n",
      "        [ 1.7951],\n",
      "        ...,\n",
      "        [ 4.5277],\n",
      "        [-0.2102],\n",
      "        [ 4.0876]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0270],\n",
      "        [0.8576],\n",
      "        ...,\n",
      "        [0.9893],\n",
      "        [0.4477],\n",
      "        [0.9835]], grad_fn=<SigmoidBackward0>)\n",
      "[128] Loss => 0.11511082202196121\n",
      "예측값 pre_y => tensor([[11.1404],\n",
      "        [-3.5855],\n",
      "        [ 1.7948],\n",
      "        ...,\n",
      "        [ 4.5299],\n",
      "        [-0.2105],\n",
      "        [ 4.0891]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0270],\n",
      "        [0.8575],\n",
      "        ...,\n",
      "        [0.9893],\n",
      "        [0.4476],\n",
      "        [0.9835]], grad_fn=<SigmoidBackward0>)\n",
      "[129] Loss => 0.11508934944868088\n",
      "예측값 pre_y => tensor([[11.1429],\n",
      "        [-3.5863],\n",
      "        [ 1.7945],\n",
      "        ...,\n",
      "        [ 4.5320],\n",
      "        [-0.2108],\n",
      "        [ 4.0907]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0270],\n",
      "        [0.8575],\n",
      "        ...,\n",
      "        [0.9894],\n",
      "        [0.4475],\n",
      "        [0.9835]], grad_fn=<SigmoidBackward0>)\n",
      "[130] Loss => 0.11506792157888412\n",
      "예측값 pre_y => tensor([[11.1455],\n",
      "        [-3.5870],\n",
      "        [ 1.7942],\n",
      "        ...,\n",
      "        [ 4.5341],\n",
      "        [-0.2111],\n",
      "        [ 4.0922]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0269],\n",
      "        [0.8574],\n",
      "        ...,\n",
      "        [0.9894],\n",
      "        [0.4474],\n",
      "        [0.9836]], grad_fn=<SigmoidBackward0>)\n",
      "[131] Loss => 0.11504654586315155\n",
      "예측값 pre_y => tensor([[11.1480],\n",
      "        [-3.5878],\n",
      "        [ 1.7939],\n",
      "        ...,\n",
      "        [ 4.5362],\n",
      "        [-0.2115],\n",
      "        [ 4.0938]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0269],\n",
      "        [0.8574],\n",
      "        ...,\n",
      "        [0.9894],\n",
      "        [0.4473],\n",
      "        [0.9836]], grad_fn=<SigmoidBackward0>)\n",
      "[132] Loss => 0.11502517014741898\n",
      "예측값 pre_y => tensor([[11.1505],\n",
      "        [-3.5885],\n",
      "        [ 1.7936],\n",
      "        ...,\n",
      "        [ 4.5383],\n",
      "        [-0.2118],\n",
      "        [ 4.0953]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0269],\n",
      "        [0.8574],\n",
      "        ...,\n",
      "        [0.9894],\n",
      "        [0.4472],\n",
      "        [0.9836]], grad_fn=<SigmoidBackward0>)\n",
      "[133] Loss => 0.11500388383865356\n",
      "예측값 pre_y => tensor([[11.1531],\n",
      "        [-3.5892],\n",
      "        [ 1.7933],\n",
      "        ...,\n",
      "        [ 4.5404],\n",
      "        [-0.2121],\n",
      "        [ 4.0968]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0269],\n",
      "        [0.8573],\n",
      "        ...,\n",
      "        [0.9894],\n",
      "        [0.4472],\n",
      "        [0.9836]], grad_fn=<SigmoidBackward0>)\n",
      "[134] Loss => 0.11498259752988815\n",
      "예측값 pre_y => tensor([[11.1556],\n",
      "        [-3.5899],\n",
      "        [ 1.7930],\n",
      "        ...,\n",
      "        [ 4.5425],\n",
      "        [-0.2125],\n",
      "        [ 4.0984]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0269],\n",
      "        [0.8573],\n",
      "        ...,\n",
      "        [0.9895],\n",
      "        [0.4471],\n",
      "        [0.9837]], grad_fn=<SigmoidBackward0>)\n",
      "[135] Loss => 0.11496138572692871\n",
      "예측값 pre_y => tensor([[11.1581],\n",
      "        [-3.5907],\n",
      "        [ 1.7927],\n",
      "        ...,\n",
      "        [ 4.5447],\n",
      "        [-0.2128],\n",
      "        [ 4.0999]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0268],\n",
      "        [0.8573],\n",
      "        ...,\n",
      "        [0.9895],\n",
      "        [0.4470],\n",
      "        [0.9837]], grad_fn=<SigmoidBackward0>)\n",
      "[136] Loss => 0.11494018882513046\n",
      "예측값 pre_y => tensor([[11.1606],\n",
      "        [-3.5914],\n",
      "        [ 1.7924],\n",
      "        ...,\n",
      "        [ 4.5468],\n",
      "        [-0.2131],\n",
      "        [ 4.1014]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0268],\n",
      "        [0.8572],\n",
      "        ...,\n",
      "        [0.9895],\n",
      "        [0.4469],\n",
      "        [0.9837]], grad_fn=<SigmoidBackward0>)\n",
      "[137] Loss => 0.11491904407739639\n",
      "예측값 pre_y => tensor([[11.1631],\n",
      "        [-3.5921],\n",
      "        [ 1.7921],\n",
      "        ...,\n",
      "        [ 4.5489],\n",
      "        [-0.2134],\n",
      "        [ 4.1029]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0268],\n",
      "        [0.8572],\n",
      "        ...,\n",
      "        [0.9895],\n",
      "        [0.4468],\n",
      "        [0.9837]], grad_fn=<SigmoidBackward0>)\n",
      "[138] Loss => 0.11489793658256531\n",
      "예측값 pre_y => tensor([[11.1656],\n",
      "        [-3.5928],\n",
      "        [ 1.7918],\n",
      "        ...,\n",
      "        [ 4.5510],\n",
      "        [-0.2138],\n",
      "        [ 4.1045]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0268],\n",
      "        [0.8571],\n",
      "        ...,\n",
      "        [0.9896],\n",
      "        [0.4468],\n",
      "        [0.9838]], grad_fn=<SigmoidBackward0>)\n",
      "[139] Loss => 0.11487685889005661\n",
      "예측값 pre_y => tensor([[11.1681],\n",
      "        [-3.5936],\n",
      "        [ 1.7914],\n",
      "        ...,\n",
      "        [ 4.5530],\n",
      "        [-0.2141],\n",
      "        [ 4.1060]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0268],\n",
      "        [0.8571],\n",
      "        ...,\n",
      "        [0.9896],\n",
      "        [0.4467],\n",
      "        [0.9838]], grad_fn=<SigmoidBackward0>)\n",
      "[140] Loss => 0.1148558259010315\n",
      "예측값 pre_y => tensor([[11.1706],\n",
      "        [-3.5943],\n",
      "        [ 1.7911],\n",
      "        ...,\n",
      "        [ 4.5551],\n",
      "        [-0.2144],\n",
      "        [ 4.1075]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0267],\n",
      "        [0.8571],\n",
      "        ...,\n",
      "        [0.9896],\n",
      "        [0.4466],\n",
      "        [0.9838]], grad_fn=<SigmoidBackward0>)\n",
      "[141] Loss => 0.11483483016490936\n",
      "예측값 pre_y => tensor([[11.1731],\n",
      "        [-3.5950],\n",
      "        [ 1.7908],\n",
      "        ...,\n",
      "        [ 4.5572],\n",
      "        [-0.2148],\n",
      "        [ 4.1090]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0267],\n",
      "        [0.8570],\n",
      "        ...,\n",
      "        [0.9896],\n",
      "        [0.4465],\n",
      "        [0.9838]], grad_fn=<SigmoidBackward0>)\n",
      "[142] Loss => 0.11481388658285141\n",
      "예측값 pre_y => tensor([[11.1756],\n",
      "        [-3.5957],\n",
      "        [ 1.7905],\n",
      "        ...,\n",
      "        [ 4.5593],\n",
      "        [-0.2151],\n",
      "        [ 4.1105]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0267],\n",
      "        [0.8570],\n",
      "        ...,\n",
      "        [0.9896],\n",
      "        [0.4464],\n",
      "        [0.9839]], grad_fn=<SigmoidBackward0>)\n",
      "[143] Loss => 0.11479296535253525\n",
      "예측값 pre_y => tensor([[11.1781],\n",
      "        [-3.5964],\n",
      "        [ 1.7902],\n",
      "        ...,\n",
      "        [ 4.5614],\n",
      "        [-0.2154],\n",
      "        [ 4.1120]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0267],\n",
      "        [0.8569],\n",
      "        ...,\n",
      "        [0.9897],\n",
      "        [0.4464],\n",
      "        [0.9839]], grad_fn=<SigmoidBackward0>)\n",
      "[144] Loss => 0.11477209627628326\n",
      "예측값 pre_y => tensor([[11.1806],\n",
      "        [-3.5972],\n",
      "        [ 1.7898],\n",
      "        ...,\n",
      "        [ 4.5635],\n",
      "        [-0.2157],\n",
      "        [ 4.1135]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0267],\n",
      "        [0.8569],\n",
      "        ...,\n",
      "        [0.9897],\n",
      "        [0.4463],\n",
      "        [0.9839]], grad_fn=<SigmoidBackward0>)\n",
      "[145] Loss => 0.11475128680467606\n",
      "예측값 pre_y => tensor([[11.1830],\n",
      "        [-3.5979],\n",
      "        [ 1.7895],\n",
      "        ...,\n",
      "        [ 4.5656],\n",
      "        [-0.2161],\n",
      "        [ 4.1151]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0267],\n",
      "        [0.8569],\n",
      "        ...,\n",
      "        [0.9897],\n",
      "        [0.4462],\n",
      "        [0.9839]], grad_fn=<SigmoidBackward0>)\n",
      "[146] Loss => 0.11473048478364944\n",
      "예측값 pre_y => tensor([[11.1855],\n",
      "        [-3.5986],\n",
      "        [ 1.7892],\n",
      "        ...,\n",
      "        [ 4.5676],\n",
      "        [-0.2164],\n",
      "        [ 4.1166]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0266],\n",
      "        [0.8568],\n",
      "        ...,\n",
      "        [0.9897],\n",
      "        [0.4461],\n",
      "        [0.9840]], grad_fn=<SigmoidBackward0>)\n",
      "[147] Loss => 0.11470972001552582\n",
      "예측값 pre_y => tensor([[11.1880],\n",
      "        [-3.5993],\n",
      "        [ 1.7889],\n",
      "        ...,\n",
      "        [ 4.5697],\n",
      "        [-0.2167],\n",
      "        [ 4.1181]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0266],\n",
      "        [0.8568],\n",
      "        ...,\n",
      "        [0.9897],\n",
      "        [0.4460],\n",
      "        [0.9840]], grad_fn=<SigmoidBackward0>)\n",
      "[148] Loss => 0.11468900740146637\n",
      "예측값 pre_y => tensor([[11.1904],\n",
      "        [-3.6000],\n",
      "        [ 1.7885],\n",
      "        ...,\n",
      "        [ 4.5718],\n",
      "        [-0.2171],\n",
      "        [ 4.1196]], grad_fn=<AddmmBackward0>)\n",
      "분류값 pre_y2 => tensor([[1.0000],\n",
      "        [0.0266],\n",
      "        [0.8567],\n",
      "        ...,\n",
      "        [0.9898],\n",
      "        [0.4459],\n",
      "        [0.9840]], grad_fn=<SigmoidBackward0>)\n",
      "[149] Loss => 0.11466831713914871\n"
     ]
    }
   ],
   "source": [
    "loss_accuracy=[[], []]\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    # 학습\n",
    "    pre_y = model(X_train) # 여기서는 1인지 0인지가 나오는 것이 아니고 W0 + W1x1.. 이 계산의 결과가 나오는 것 \n",
    "    print(f\"예측값 pre_y => {pre_y}\")\n",
    "    \n",
    "    # 분류값 변환\n",
    "    pre_y2 = F.sigmoid(pre_y)\n",
    "    print(f\"분류값 pre_y2 => {pre_y2}\")\n",
    "    \n",
    "    \n",
    "    # 오차 cost function 계산\n",
    "    loss = F.binary_cross_entropy(pre_y2, y_train)\n",
    "    loss_accuracy[0].append(loss.item())\n",
    "    #  loss_list.append(loss.item())\n",
    "    print(f\"[{ep}] Loss => {loss}\")\n",
    "    \n",
    "    # W, b 업데이트\n",
    "    optimizer.zero_grad() # \n",
    "    loss.backward() # 손실함수 계산 값으로 미분 진행 W, b 계산\n",
    "    optimizer.step() # backward에서 계산 W, b 업데이트\n",
    "    \n",
    "    # 정확도 계산 => 예측값을 0과 1로 변환 => 정답과 비교 \n",
    "    train_accuracy = (y_train == (pre_y2 >= 0.5)).sum() / y_train.shape[0]\n",
    "    loss_accuracy[1].append(train_accuracy.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:05:20.632651900Z",
     "start_time": "2024-03-14T05:05:18.638260500Z"
    }
   },
   "id": "db873ab8e1588b7a",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9566)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train == (pre_y2 >= 0.5)).sum() / y_train.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:05:20.644156700Z",
     "start_time": "2024-03-14T05:05:20.629610100Z"
    }
   },
   "id": "479738cd58442ecf",
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 손실과 정확도 시각화"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c08e993528c6ab08"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(loss_accuracy[0], label='loss', color=\"g\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(loss_accuracy[1],label='accuracy', color='r')\n",
    "# plt.plot(loss_accuracy[0], label='loss')\n",
    "# plt.plot(loss_accuracy[1], label='accuracy')\n",
    "\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T05:13:28.058410300Z",
     "start_time": "2024-03-14T05:13:27.902999Z"
    }
   },
   "id": "b46397421840ee0a",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f16611f465e6d21b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
